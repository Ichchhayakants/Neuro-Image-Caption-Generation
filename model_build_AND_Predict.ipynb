{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"Untitled10.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"id":"8ONpfOeMyHuC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":525},"outputId":"fab84a94-4d93-49b3-8bc5-27ac39babb21","executionInfo":{"status":"ok","timestamp":1586206205043,"user_tz":-330,"elapsed":5855,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["from numpy import array\n","from pickle import load\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.layers import Dropout\n","from keras.layers.merge import add\n","from keras.callbacks import ModelCheckpoint"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"yS4UnYD2QfXx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"d661a905-1fe3-490d-e525-8a2a1e13d22e","executionInfo":{"status":"ok","timestamp":1586206227909,"user_tz":-330,"elapsed":5838,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["!pip3 show tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Name: tensorflow\n","Version: 1.14.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.6/dist-packages\n","Requires: absl-py, gast, google-pasta, keras-applications, protobuf, grpcio, wheel, six, tensorboard, termcolor, wrapt, astor, keras-preprocessing, tensorflow-estimator, numpy\n","Required-by: fancyimpute\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UPcIH4MPyHuL","colab_type":"code","colab":{}},"source":["# load doc into memory\n","def load_doc(filename):\n","    # open the file as read only\n","    file = open(filename, 'r')\n","    # read all text\n","    text = file.read()\n","    # close the file\n","    file.close()\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKPVh_unyHuS","colab_type":"code","colab":{}},"source":["# load a pre-defined list of photo identifiers\n","def load_set(filename):\n","    doc = load_doc(filename)\n","    dataset = list()\n","    # process line by line\n","    for line in doc.split('\\n'):\n","        # skip empty lines\n","        if len(line) < 1:\n","            continue\n","        # get the image identifier\n","        identifier = line.split('.')[0]\n","        dataset.append(identifier)\n","    return set(dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibHpKN5ByHuX","colab_type":"code","colab":{}},"source":["# load clean descriptions into memory\n","def load_clean_descriptions(filename, dataset):\n","    # load document\n","    doc = load_doc(filename)\n","    descriptions = dict()\n","    for line in doc.split('\\n'):\n","        # split line by white space\n","        tokens = line.split()\n","        # split id from description\n","        image_id, image_desc = tokens[0], tokens[1:]\n","        # skip images not in the set\n","        if image_id in dataset:\n","            # create list\n","            if image_id not in descriptions:\n","                descriptions[image_id] = list()\n","            # wrap description in tokens\n","            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","            # store\n","            descriptions[image_id].append(desc)\n","    return descriptions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sy-YGp54yHud","colab_type":"code","colab":{}},"source":["# load photo features\n","def load_photo_features(filename, dataset):\n","    # load all features\n","    all_features = load(open(filename, 'rb'))\n","    # filter features\n","    features = {k: all_features[k] for k in dataset}\n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7XE6A6AyHuj","colab_type":"code","colab":{}},"source":["# convert a dictionary of clean descriptions to a list of descriptions\n","def to_lines(descriptions):\n","    all_desc = list()\n","    for key in descriptions.keys():\n","        [all_desc.append(d) for d in descriptions[key]]\n","    return all_desc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_n-NdS5yHuo","colab_type":"code","colab":{}},"source":["# fit a tokenizer given caption descriptions\n","def create_tokenizer(descriptions):\n","    lines = to_lines(descriptions)\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(lines)\n","    return tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qF4VU1RlyHuu","colab_type":"code","colab":{}},"source":["# calculate the length of the description with the most words\n","def max_len(descriptions):\n","    lines = to_lines(descriptions)\n","    return max(len(d.split()) for d in lines)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jf--CopjyHuz","colab_type":"code","colab":{}},"source":["# create sequences of images, input sequences and output words for an image\n","def create_sequences(tokenizer, max_length, descriptions, photos):\n","    X1, X2, y = list(), list(), list()\n","    # walk through each image identifier\n","    for key, desc_list in descriptions.items():\n","        # walk through each description for the image\n","        for desc in desc_list:\n","            # encode the sequence\n","            seq = tokenizer.texts_to_sequences([desc])[0]\n","            # split one sequence into multiple X,y pairs\n","            for i in range(1, len(seq)):\n","                # split into input and output pair\n","                in_seq, out_seq = seq[:i], seq[i]\n","                # pad input sequence\n","                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","                # encode output sequence\n","                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","                # store\n","                X1.append(photos[key][0])\n","                X2.append(in_seq)\n","                y.append(out_seq)\n","    return array(X1), array(X2), array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0N1FT-HWyHu4","colab_type":"code","colab":{}},"source":["# define the captioning model\n","def define_model(vocab_size, max_length):\n","    # feature extractor model\n","    inputs1 = Input(shape=(4096,))\n","    fe1 = Dropout(0.5)(inputs1)\n","    fe2 = Dense(256, activation='relu')(fe1)\n","    # sequence model\n","    inputs2 = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","    se2 = Dropout(0.5)(se1)\n","    se3 = LSTM(256)(se2)\n","    # decoder model\n","    decoder1 = add([fe2, se3])\n","    decoder2 = Dense(256, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","    # tie it together [image, seq] [word]\n","    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","    # compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    # summarize model\n","    model.summary()\n","    #plot_model(model, to_file='model.png', show_shapes=True)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WD0GQYTdyHu-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"f800986b-4dc7-41fc-d2c9-060551fb8ef5","executionInfo":{"status":"ok","timestamp":1586206301146,"user_tz":-330,"elapsed":35073,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load training dataset (6K)\n","filename = 'Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))\n","# descriptions\n","train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","# photo features\n","train_features = load_photo_features('features.pkl', train)\n","print('Photos: train=%d' % len(train_features))\n","# prepare tokenizer\n","tokenizer = create_tokenizer(train_descriptions)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)\n","# determine the maximum sequence length\n","max_length = max_length(train_descriptions)\n","print('Description Length: %d' % max_length)\n","# prepare sequences\n","X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions,\n","train_features)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Dataset: 6000\n","Descriptions: train=6000\n","Photos: train=6000\n","Vocabulary Size: 7579\n","Description Length: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MKQaEPH2yHvD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"710f708f-5435-425d-9368-608fef8492c0","executionInfo":{"status":"ok","timestamp":1586206315405,"user_tz":-330,"elapsed":5678,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load test set\n","filename = 'Flickr_8k.devImages.txt'\n","test = load_set(filename)\n","print('Dataset: %d' % len(test))\n","# descriptions\n","test_descriptions = load_clean_descriptions('descriptions.txt', test)\n","print('Descriptions: test=%d' % len(test_descriptions))\n","# photo features\n","test_features = load_photo_features('features.pkl', test)\n","print('Photos: test=%d' % len(test_features))\n","# prepare sequences\n","X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions,\n","test_features)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Dataset: 1000\n","Descriptions: test=1000\n","Photos: test=1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2w5JvmqjyHvJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":836},"outputId":"61c105b9-e5b4-4b3b-c9e0-fee8f4622332","executionInfo":{"status":"ok","timestamp":1586206318884,"user_tz":-330,"elapsed":1760,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# define the model\n","model = define_model(vocab_size, max_length)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 34)           0                                            \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            (None, 4096)         0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 34, 256)      1940224     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 4096)         0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 34, 256)      0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n","                                                                 lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 7579)         1947803     dense_2[0][0]                    \n","==================================================================================================\n","Total params: 5,527,963\n","Trainable params: 5,527,963\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YpXyY2GeyHvN","colab_type":"code","colab":{}},"source":["# define checkpoint callback\n","checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1,\n","                             save_best_only=True, mode='min')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6KGeBOJyHvR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"823549c2-0030-4543-899f-d056d6dbf932","executionInfo":{"status":"ok","timestamp":1586240026458,"user_tz":-330,"elapsed":7226175,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# fit model\n","model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint],\n","          validation_data=([X1test, X2test], ytest))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Train on 306404 samples, validate on 50903 samples\n","Epoch 1/20\n"," - 1657s - loss: 4.5186 - val_loss: 4.0642\n","\n","Epoch 00001: val_loss improved from inf to 4.06424, saving model to model.h5\n","Epoch 2/20\n"," - 1659s - loss: 3.8833 - val_loss: 3.9211\n","\n","Epoch 00002: val_loss improved from 4.06424 to 3.92111, saving model to model.h5\n","Epoch 3/20\n"," - 1647s - loss: 3.6930 - val_loss: 3.8661\n","\n","Epoch 00003: val_loss improved from 3.92111 to 3.86614, saving model to model.h5\n","Epoch 4/20\n"," - 1671s - loss: 3.5979 - val_loss: 3.8466\n","\n","Epoch 00004: val_loss improved from 3.86614 to 3.84664, saving model to model.h5\n","Epoch 5/20\n"," - 1652s - loss: 3.5443 - val_loss: 3.8564\n","\n","Epoch 00005: val_loss did not improve from 3.84664\n","Epoch 6/20\n"," - 1734s - loss: 3.5096 - val_loss: 3.8636\n","\n","Epoch 00006: val_loss did not improve from 3.84664\n","Epoch 7/20\n"," - 1722s - loss: 3.4883 - val_loss: 3.8786\n","\n","Epoch 00007: val_loss did not improve from 3.84664\n","Epoch 8/20\n"," - 1742s - loss: 3.4746 - val_loss: 3.8777\n","\n","Epoch 00008: val_loss did not improve from 3.84664\n","Epoch 9/20\n"," - 1719s - loss: 3.4682 - val_loss: 3.9065\n","\n","Epoch 00009: val_loss did not improve from 3.84664\n","Epoch 10/20\n"," - 1718s - loss: 3.4587 - val_loss: 3.9119\n","\n","Epoch 00010: val_loss did not improve from 3.84664\n","Epoch 11/20\n"," - 1687s - loss: 3.4633 - val_loss: 3.9260\n","\n","Epoch 00011: val_loss did not improve from 3.84664\n","Epoch 12/20\n"," - 1732s - loss: 3.4684 - val_loss: 3.9308\n","\n","Epoch 00012: val_loss did not improve from 3.84664\n","Epoch 13/20\n"," - 1680s - loss: 3.4693 - val_loss: 3.9450\n","\n","Epoch 00013: val_loss did not improve from 3.84664\n","Epoch 14/20\n"," - 1674s - loss: 3.4689 - val_loss: 3.9673\n","\n","Epoch 00014: val_loss did not improve from 3.84664\n","Epoch 15/20\n"," - 1661s - loss: 3.4718 - val_loss: 3.9810\n","\n","Epoch 00015: val_loss did not improve from 3.84664\n","Epoch 16/20\n"," - 1663s - loss: 3.4767 - val_loss: 3.9907\n","\n","Epoch 00016: val_loss did not improve from 3.84664\n","Epoch 17/20\n"," - 1669s - loss: 3.4780 - val_loss: 3.9939\n","\n","Epoch 00017: val_loss did not improve from 3.84664\n","Epoch 18/20\n"," - 1661s - loss: 3.4823 - val_loss: 4.0116\n","\n","Epoch 00018: val_loss did not improve from 3.84664\n","Epoch 19/20\n"," - 1683s - loss: 3.4815 - val_loss: 4.0117\n","\n","Epoch 00019: val_loss did not improve from 3.84664\n","Epoch 20/20\n"," - 1665s - loss: 3.4868 - val_loss: 4.0208\n","\n","Epoch 00020: val_loss did not improve from 3.84664\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f5284e7feb8>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ew517kkzyHvV","colab_type":"code","colab":{}},"source":["from numpy import argmax\n","from pickle import load\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dKS7_oq0-Nh","colab_type":"code","colab":{}},"source":["# map an integer to a word\n","def word_for_id(integer, tokenizer):\n","    for word, index in tokenizer.word_index.items():\n","        if index == integer:\n","            return word\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WPzaKtjy1DEQ","colab_type":"code","colab":{}},"source":["# generate a description for an image\n","def generate_desc(model, tokenizer, photo, max_length):\n","    # seed the generation process\n","    in_text = 'startseq'\n","    # iterate over the whole length of the sequence\n","    for _ in range(max_length):\n","        # integer encode input sequence\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        # pad input\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        # predict next word\n","        yhat = model.predict([photo,sequence], verbose=0)\n","        # convert probability to integer\n","        yhat = argmax(yhat)\n","        # map integer to word\n","        word = word_for_id(yhat, tokenizer)\n","        # stop if we cannot map the word\n","        if word is None:\n","            break\n","        # append as input for generating the next word\n","        in_text += ' ' + word\n","        # stop if we predict the end of the sequence\n","        if word == 'endseq':\n","            break\n","    return in_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0QuC3dx1Iqj","colab_type":"code","colab":{}},"source":["# remove start/end sequence tokens from a summary\n","def cleanup_summary(summary):\n","    # remove start of sequence token\n","    index = summary.find('startseq ')\n","    if index > -1:\n","        summary = summary[len('startseq '):]\n","    # remove end of sequence token\n","    index = summary.find(' endseq')\n","    if index > -1:\n","      summary = summary[:index]\n","    return summary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBzLFtfy1MI0","colab_type":"code","colab":{}},"source":["# evaluate the skill of the model\n","def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n","    actual, predicted = list(), list()\n","    # step over the whole set\n","    for key, desc_list in descriptions.items():\n","        # generate description\n","        yhat = generate_desc(model, tokenizer, photos[key], max_length)\n","        # clean up prediction\n","        yhat = cleanup_summary(yhat)\n","        # store actual and predicted\n","        references = [cleanup_summary(d).split() for d in desc_list]\n","        actual.append(references)\n","        predicted.append(yhat.split())\n","        # calculate BLEU score\n","    # calculate BLEU score\n","    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n","    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7O-oaDgY1P7K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"2f0eebff-3fb9-46cc-f219-bceb1c336a16","executionInfo":{"status":"ok","timestamp":1586241645705,"user_tz":-330,"elapsed":1456,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load training dataset (6K)\n","filename = 'Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))\n","# descriptions\n","train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","# prepare tokenizer\n","tokenizer = create_tokenizer(train_descriptions)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)\n","# determine the maximum sequence length\n","max_leng = max_len(train_descriptions)\n","print('Description Length: %d' % max_leng)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Dataset: 6000\n","Descriptions: train=6000\n","Vocabulary Size: 7579\n","Description Length: 34\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nXHdPZAp1aHV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"cbb6ea6e-eba4-48a7-f9c7-50091d945b9e","executionInfo":{"status":"ok","timestamp":1586241668190,"user_tz":-330,"elapsed":974,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load test set\n","filename = 'Flickr_8k.testImages.txt'\n","test = load_set(filename)\n","print('Dataset: %d' % len(test))\n","# descriptions\n","test_descriptions = load_clean_descriptions('descriptions.txt', test)\n","print('Descriptions: test=%d' % len(test_descriptions))\n","# photo features\n","test_features = load_photo_features('features.pkl', test)\n","print('Photos: test=%d' % len(test_features))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Dataset: 1000\n","Descriptions: test=1000\n","Photos: test=1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NR7QM3kL1fFr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"30089583-f412-4c09-8bdf-bd642c279c9c","executionInfo":{"status":"ok","timestamp":1586241769577,"user_tz":-330,"elapsed":94943,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load the model\n","filename = 'model.h5'\n","model = load_model(filename)\n","# evaluate model\n","evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["BLEU-1: 0.410004\n","BLEU-2: 0.216114\n","BLEU-3: 0.144737\n","BLEU-4: 0.060444\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6pCQzh7x1jmH","colab_type":"code","colab":{}},"source":["from keras.preprocessing.text import Tokenizer\n","from pickle import dump"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxAsP0ka1kuc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"61fadf01-10c1-43e3-f800-da2a525f769e","executionInfo":{"status":"ok","timestamp":1586241784452,"user_tz":-330,"elapsed":1585,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["# load training dataset\n","filename = 'Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))\n","# descriptions\n","train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","# prepare tokenizer\n","tokenizer = create_tokenizer(train_descriptions)\n","# save the tokenizer\n","dump(tokenizer, open('tokenizer.pkl', 'wb'))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Dataset: 6000\n","Descriptions: train=6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qZ0ppcr211UN","colab_type":"code","colab":{}},"source":["# load the tokenizer\n","tokenizer = load(open('tokenizer.pkl', 'rb'))\n","# pre-define the max sequence length (from training)\n","max_length = 34"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBSds6Iy13kf","colab_type":"code","colab":{}},"source":["# load the model\n","model = load_model('model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWeKY_AgYmxr","colab_type":"code","colab":{}},"source":["from keras.applications.vgg16 import VGG16"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqiCiK5YZYkx","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRWniDs01716","colab_type":"code","colab":{}},"source":["# extract features from each photo in the directory\n","def extract_features(filename):\n","    # load the model\n","    model = VGG16()\n","    # re-structure the model\n","    model.layers.pop()\n","    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n","    # load the photo\n","    image = load_img(filename, target_size=(224, 224))\n","    # convert the image pixels to a NumPy array\n","    image = img_to_array(image)\n","    # reshape data for the model\n","    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","    # prepare the image for the VGG model\n","    image = preprocess_input(image)\n","    # get features\n","    feature = model.predict(image, verbose=0)\n","    return feature"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e094QbA22Axn","colab_type":"code","colab":{}},"source":["# load and prepare the photograph\n","photo = extract_features('example1.jpg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkjxzAEEZd0g","colab_type":"code","colab":{}},"source":["# Generate description\n","description = generate_desc(model,tokenizer,photo,max_length)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1Hq2bi0aebw","colab_type":"code","colab":{}},"source":["description = cleanup_summary(description)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uk1k0w6Yamj9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"05576579-e525-47d5-eedf-8a80680b9297","executionInfo":{"status":"ok","timestamp":1586242551381,"user_tz":-330,"elapsed":1727,"user":{"displayName":"Ichchhayakant Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMh1bxT1X2s4IHPAHAo_5vqqm0y1JKV7PLWZEgMA=s64","userId":"04533860475182717085"}}},"source":["print(description)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["man in red shirt is standing on the top of the ground\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bX3gcQnapJi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}